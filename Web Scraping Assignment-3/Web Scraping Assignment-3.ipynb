{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60d6d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9dd43d",
   "metadata": {},
   "source": [
    "### 1.Write a python program which searches all the product under a particular product from www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6fe68cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c23e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b497afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "guitar=driver.find_element(By.XPATH,\"//div[@class='nav-search-field ']//input\")\n",
    "guitar.send_keys('guitar')\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f148ac",
   "metadata": {},
   "source": [
    "### 2. In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then scrape all the products available under that product name. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e897da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_urls=[]\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    url=driver.find_elements(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[3]/div/div/div/div/div/div/div[2]/div[1]/h2/a')\n",
    "    for i in url:\n",
    "        product_urls.append(i.get_attribute(\"href\"))\n",
    "    nxt_button=driver.find_element(By.XPATH,'//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')\n",
    "    nxt_button.click()\n",
    "    time.sleep(2)\n",
    "#brand_name    \n",
    "brand_name=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'//span[@class=\"a-size-base a-color-tertiary\"]')\n",
    "        brand_name.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_name.append('-')\n",
    "\n",
    "        \n",
    "#name_of_product\n",
    "name_of_product=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        product=driver.find_element(By.XPATH,'//h1[@id=\"title\"]')\n",
    "        name_of_product.append(product.text)\n",
    "    except NoSuchElementException:\n",
    "        name_of_product.append('-')\n",
    "        \n",
    "#price\n",
    "price=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        prc=driver.find_element(By.XPATH,'//span[@class=\"a-offscreen\"]')\n",
    "        price.append(prc.text)\n",
    "    except NoSuchElementException:\n",
    "        price.append('-') \n",
    "        \n",
    "        \n",
    "#return_exchange\n",
    "return_exchange=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        re=driver.find_element(By.XPATH,'//a[@class=\"a-size-small a-link-normal a-text-normal\"]')\n",
    "        return_exchange.append(re.text.split(' ')[2])\n",
    "    except NoSuchElementException:\n",
    "        return_exchange.append('-')\n",
    "        \n",
    "#expected_delivery\n",
    "expected_delivery=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        ed=driver.find_element(By.XPATH,'//span[@class=\"a-text-bold\"]')\n",
    "        expected_delivery.append(ed.text)\n",
    "    except NoSuchElementException:\n",
    "        expected_delivery.append('-')\n",
    "\n",
    "#availability\n",
    "availability=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        avail=driver.find_element(By.XPATH,'//div[@id=\"availability\"]')\n",
    "        availability.append(avail.text)\n",
    "    except NoSuchElementException:\n",
    "        availability.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f3a59b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>name_of_product</th>\n",
       "      <th>price</th>\n",
       "      <th>return_exchange</th>\n",
       "      <th>expected_delivery</th>\n",
       "      <th>availability</th>\n",
       "      <th>product_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kadence</td>\n",
       "      <td>Kadence Frontier guitar with Online Guitar lea...</td>\n",
       "      <td></td>\n",
       "      <td>Delivery</td>\n",
       "      <td>Sunday, 2 October</td>\n",
       "      <td></td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guitar Bro</td>\n",
       "      <td>GUITAR BRO - COMBO (Blue Acoustic Guitar for B...</td>\n",
       "      <td></td>\n",
       "      <td>Replacement</td>\n",
       "      <td>October 3 - 6</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KREEPO</td>\n",
       "      <td>KREEPO Guitar Fretboard Sticker Fingerboard Fr...</td>\n",
       "      <td></td>\n",
       "      <td>Replacement</td>\n",
       "      <td>Sunday, 2 October</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_name                                    name_of_product price  \\\n",
       "0     Kadence  Kadence Frontier guitar with Online Guitar lea...         \n",
       "1  Guitar Bro  GUITAR BRO - COMBO (Blue Acoustic Guitar for B...         \n",
       "2      KREEPO  KREEPO Guitar Fretboard Sticker Fingerboard Fr...         \n",
       "\n",
       "  return_exchange  expected_delivery availability  \\\n",
       "0        Delivery  Sunday, 2 October                \n",
       "1     Replacement      October 3 - 6    In stock.   \n",
       "2     Replacement  Sunday, 2 October    In stock.   \n",
       "\n",
       "                                        product_urls  \n",
       "0  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "1  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "2  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'brand_name':brand_name,'name_of_product':name_of_product,'price':price,'return_exchange':return_exchange,'expected_delivery':expected_delivery,'availability':availability,'product_urls':product_urls})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e23c3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a94ccc",
   "metadata": {},
   "source": [
    "### 3. Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58a58289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79f39be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://images.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f1c8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input')\n",
    "search.send_keys('fruits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f60967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "select=driver.find_element(By.XPATH,'//div[@class=\"zgAlFc\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "683144b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "61acabd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 images\n",
      "Downloading 1 of 10 images\n",
      "Downloading 2 of 10 images\n",
      "Downloading 3 of 10 images\n",
      "Downloading 4 of 10 images\n",
      "Downloading 5 of 10 images\n",
      "Downloading 6 of 10 images\n",
      "Downloading 7 of 10 images\n",
      "Downloading 8 of 10 images\n",
      "Downloading 9 of 10 images\n",
      "Downloading 10 of 10 images\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    driver.execute_script (\"window.scrollBy (0,1800)\")\n",
    "    \n",
    "images=driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')\n",
    "img_urls=[]\n",
    "img_data=[]\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] =='http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 10))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\vikas\\Desktop\\fliprobo\\New folder\"+str(i)+\"-jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8486e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ceb415ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cars\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://images.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d0106ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input')\n",
    "search.send_keys('cars')\n",
    "select=driver.find_element(By.XPATH,'//div[@class=\"zgAlFc\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55b27c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 images\n",
      "Downloading 1 of 10 images\n",
      "Downloading 2 of 10 images\n",
      "Downloading 3 of 10 images\n",
      "Downloading 4 of 10 images\n",
      "Downloading 5 of 10 images\n",
      "Downloading 6 of 10 images\n",
      "Downloading 7 of 10 images\n",
      "Downloading 8 of 10 images\n",
      "Downloading 9 of 10 images\n",
      "Downloading 10 of 10 images\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    driver.execute_script (\"window.scrollBy (0,1800)\")\n",
    "    \n",
    "images=driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')\n",
    "img_urls=[]\n",
    "img_data=[]\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] =='http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 10))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\vikas\\Desktop\\fliprobo\\New folder\"+str(i)+\"-jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01512481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://images.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0043e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input')\n",
    "search.send_keys('Machine Learning')\n",
    "select=driver.find_element(By.XPATH,'//div[@class=\"zgAlFc\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dad2acbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 images\n",
      "Downloading 1 of 10 images\n",
      "Downloading 2 of 10 images\n",
      "Downloading 3 of 10 images\n",
      "Downloading 4 of 10 images\n",
      "Downloading 5 of 10 images\n",
      "Downloading 6 of 10 images\n",
      "Downloading 7 of 10 images\n",
      "Downloading 8 of 10 images\n",
      "Downloading 9 of 10 images\n",
      "Downloading 10 of 10 images\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    driver.execute_script (\"window.scrollBy (0,1800)\")\n",
    "    \n",
    "images=driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')\n",
    "img_urls=[]\n",
    "img_data=[]\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] =='http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 10))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\vikas\\Desktop\\fliprobo\\New folder\"+str(i)+\"-jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5419d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guitar\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://images.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5c04b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input')\n",
    "search.send_keys('Guitar')\n",
    "select=driver.find_element(By.XPATH,'//div[@class=\"zgAlFc\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a89412f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    driver.execute_script (\"window.scrollBy (0,1800)\")\n",
    "    \n",
    "images=driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')\n",
    "img_urls=[]\n",
    "img_data=[]\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] =='http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 10))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\vikas\\Desktop\\fliprobo\\New folder\"+str(i)+\"-jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3edd9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cakes\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://images.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "09bb1506",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input')\n",
    "search.send_keys('Cakes')\n",
    "select=driver.find_element(By.XPATH,'//div[@class=\"zgAlFc\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a4d0ef47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 images\n",
      "Downloading 1 of 10 images\n",
      "Downloading 2 of 10 images\n",
      "Downloading 3 of 10 images\n",
      "Downloading 4 of 10 images\n",
      "Downloading 5 of 10 images\n",
      "Downloading 6 of 10 images\n",
      "Downloading 7 of 10 images\n",
      "Downloading 8 of 10 images\n",
      "Downloading 9 of 10 images\n",
      "Downloading 10 of 10 images\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    driver.execute_script (\"window.scrollBy (0,1800)\")\n",
    "    \n",
    "images=driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')\n",
    "img_urls=[]\n",
    "img_data=[]\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] =='http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 10))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\vikas\\Desktop\\fliprobo\\New folder\"+str(i)+\"-jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dacf3e",
   "metadata": {},
   "source": [
    "### 4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aa33a88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"http://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e66321a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "designation.send_keys('smartphone')\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cfebf515",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_urls=[]\n",
    "start=0\n",
    "end=1\n",
    "for page in range(start,end):\n",
    "    url=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a')\n",
    "    for i in url:\n",
    "        product_urls.append(i.get_attribute(\"href\"))    \n",
    "    time.sleep(5)\n",
    "    read_more=driver.find_element(By.XPATH,'')\n",
    "    read_more.click()\n",
    "    \n",
    "#brand_name    \n",
    "brand_name=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'//span[@class=\"B_NuCI\"]')\n",
    "        brand_name.append(brand.text.split(' ')[0])\n",
    "    except NoSuchElementException:\n",
    "        brand_name.append('-')\n",
    "\n",
    "        \n",
    "#smartphone_name\n",
    "smartphone_name=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        product=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div/div[1]/table/tbody/tr[3]/td[2]/ul/li')\n",
    "        smartphone_name.append(product.text)\n",
    "    except NoSuchElementException:\n",
    "        smartphone_name.append('-')\n",
    "        \n",
    "#colour\n",
    "colour=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        clr=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div/div[1]/table/tbody/tr[4]/td[2]/ul/li')\n",
    "        colour.append(clr.text)\n",
    "    except NoSuchElementException:\n",
    "        colour.append('-') \n",
    "\n",
    "#ram\n",
    "RAM=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        ram=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[4]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "        RAM.append(ram.text)\n",
    "    except NoSuchElementException:\n",
    "        RAM.append('-')\n",
    "        \n",
    "#rom\n",
    "ROM=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        rom=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[4]/table/tbody/tr[1]/td[2]/ul/li')\n",
    "        ROM.append(rom.text)\n",
    "    except NoSuchElementException:\n",
    "        ROM.append('-')\n",
    "        \n",
    "#primary_camera\n",
    "primary_camera=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        pc=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[5]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "        primary_camera.append(pc.text)\n",
    "    except NoSuchElementException:\n",
    "        primary_camera.append('-')\n",
    "        \n",
    "\n",
    "#secondary_camera\n",
    "secondary_camera=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        sc=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[5]/table/tbody/tr[6]/td[2]/ul/li')\n",
    "        secondary_camera.append(sc.text)\n",
    "    except NoSuchElementException:\n",
    "        secondary_camera.append('-')\n",
    "        \n",
    "        \n",
    "#display_size\n",
    "display_size=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        ds=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[2]/table/tbody/tr[1]/td[2]/ul/li')\n",
    "        display_size.append(ds.text)\n",
    "    except NoSuchElementException:\n",
    "        display_size.append('-')\n",
    "        \n",
    "#battery_capacity\n",
    "battery_capacity=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        bc=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[5]/div/div[2]/div[1]/div[10]/table/tbody/tr[1]/td[2]/ul/li')\n",
    "        battery_capacity.append(bc.text)\n",
    "    except NoSuchElementException:\n",
    "        battery_capacity.append('-')\n",
    "\n",
    "#price\n",
    "price=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        prc=driver.find_element(By.XPATH,'//div[@class=\"_30jeq3 _16Jk6d\"]')\n",
    "        price.append(prc.text)\n",
    "    except NoSuchElementException:\n",
    "        price.append('-')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "77ce6a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>smartphone_name</th>\n",
       "      <th>colour</th>\n",
       "      <th>RAM</th>\n",
       "      <th>ROM</th>\n",
       "      <th>primary_camera</th>\n",
       "      <th>secondary_camera</th>\n",
       "      <th>display_size</th>\n",
       "      <th>battery_capacity</th>\n",
       "      <th>price</th>\n",
       "      <th>product_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAMSUNG</td>\n",
       "      <td>Galaxy F13</td>\n",
       "      <td>Nightsky Green</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>₹9,499</td>\n",
       "      <td>https://www.flipkart.com/samsung-galaxy-f13-ni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  brand_name smartphone_name          colour RAM ROM primary_camera  \\\n",
       "0    SAMSUNG      Galaxy F13  Nightsky Green                          \n",
       "\n",
       "  secondary_camera display_size battery_capacity   price  \\\n",
       "0                                                 ₹9,499   \n",
       "\n",
       "                                        product_urls  \n",
       "0  https://www.flipkart.com/samsung-galaxy-f13-ni...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'brand_name':brand_name,'smartphone_name':smartphone_name,'colour':colour,'RAM':RAM,'ROM':ROM,'primary_camera':primary_camera,'secondary_camera':secondary_camera,'display_size':display_size,'battery_capacity':battery_capacity,'price':price,'product_urls':product_urls})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f170734",
   "metadata": {},
   "source": [
    "### 5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e89373da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c34c7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://www.google.co.in/maps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6b44d209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter City Name : giridih\n"
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "city = input('Enter City Name : ')                                         \n",
    "search = driver.find_element(By.ID,\"searchboxinput\")                     \n",
    "search.clear()                                                             \n",
    "time.sleep(2)\n",
    "search.send_keys(city)                                                     \n",
    "button = driver.find_element(By.ID,\"searchbox-searchbutton\")               \n",
    "button.click()                                                             \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4ab9bce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Extracted:  https://www.google.co.in/maps/place/Giridih,+Jharkhand/@24.1899243,86.2544302,13z/data=!3m1!4b1!4m5!3m4!1s0x39f155d71e2ff95d:0xa5bea10ff8ed8188!8m2!3d24.19135!4d86.2996368\n",
      "Latitude = 24.1899243, Longitude = 86.2544302\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    url_string = driver.current_url\n",
    "    print(\"URL Extracted: \", url_string)\n",
    "    lat_lng = re.findall(r'@(.*)data',url_string)\n",
    "    if len(lat_lng):\n",
    "        lat_lng_list = lat_lng[0].split(\",\")\n",
    "        if len(lat_lng_list)>=2:\n",
    "            lat = lat_lng_list[0]\n",
    "            lng = lat_lng_list[1]\n",
    "        print(\"Latitude = {}, Longitude = {}\".format(lat, lng))\n",
    "\n",
    "except Exception as e:\n",
    "        print(\"Error: \", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e569342",
   "metadata": {},
   "source": [
    "### 6. Write a program to scrap details of all the funding deals for second quarter (i.e Jan 21 – March 21) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "02d36b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://trak.in/india-startup-funding-investment-2015/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e7c6d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dates=[]\n",
    "Company=[]\n",
    "Industry=[]\n",
    "Investor_Name=[]\n",
    "Investment_Type=[]\n",
    "Amount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0668aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the company_name \n",
    "companies=driver.find_elements(By.XPATH,\"//td[@class='column-3']\")\n",
    "for i in companies[5:29]:\n",
    "    if i.text is None :\n",
    "        Company.append(\"--\") \n",
    "    else:\n",
    "        Company.append(i.text)\n",
    "#scraping the Industry \n",
    "Ind=driver.find_elements(By.XPATH,\"//td[@class='column-4']\")\n",
    "for i in Ind[5:29]:\n",
    "    if i.text is None :\n",
    "        Industry.append(\"--\") \n",
    "    else:\n",
    "        Industry.append(i.text)\n",
    "        \n",
    "#scraping the Dates \n",
    "dt=driver.find_elements(By.XPATH,\"//td[@class='column-2']\")\n",
    "for i in dt[5:29]:\n",
    "    if i.text is None :\n",
    "        Dates.append(\"--\") \n",
    "    else:\n",
    "        Dates.append(i.text)\n",
    "        \n",
    "#scraping the Investor_Name \n",
    "IN=driver.find_elements(By.XPATH,\"//td[@class='column-7']\")\n",
    "for i in IN[5:29]:\n",
    "    if i.text is None :\n",
    "        Investor_Name.append(\"--\") \n",
    "    else:\n",
    "        Investor_Name.append(i.text)\n",
    "        \n",
    "#scraping the Investment_Type \n",
    "IT=driver.find_elements(By.XPATH,\"//td[@class='column-8']\")\n",
    "for i in IT[5:29]:\n",
    "    if i.text is None :\n",
    "        Investment_Type.append(\"--\") \n",
    "    else:\n",
    "        Investment_Type.append(i.text)\n",
    "        \n",
    "#scraping the Amount \n",
    "Price=driver.find_elements(By.XPATH,\"//td[@class='column-9']\")\n",
    "for i in Price[5:29]:\n",
    "    if i.text is None :\n",
    "        Amount.append(\"--\") \n",
    "    else:\n",
    "        Amount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "238b220e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Investor_Name</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Investment_Type</th>\n",
       "      <th>Dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DealShare</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Innoven Capital</td>\n",
       "      <td>250,000,000</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>04/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uniphore</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Sorenson Capital Partners</td>\n",
       "      <td>140,000,000</td>\n",
       "      <td>Series D</td>\n",
       "      <td>31/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dunzo</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Krishtal Advisors Pte Ltd</td>\n",
       "      <td>8,000,000</td>\n",
       "      <td>Series E</td>\n",
       "      <td>30/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BYJU’S</td>\n",
       "      <td>Edu-tech</td>\n",
       "      <td>MC Global Edtech, B Capital, Baron, others</td>\n",
       "      <td>460,000,000</td>\n",
       "      <td>Series F</td>\n",
       "      <td>30/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SkilloVilla</td>\n",
       "      <td>Edu-tech</td>\n",
       "      <td>Titan Capital, others</td>\n",
       "      <td>300,000,000</td>\n",
       "      <td>Seed</td>\n",
       "      <td>23/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CityMall</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Accel Partners</td>\n",
       "      <td>11,000,000</td>\n",
       "      <td>Series A</td>\n",
       "      <td>25/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DotPe</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>PayU</td>\n",
       "      <td>27,500,000</td>\n",
       "      <td>Series A</td>\n",
       "      <td>26/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Doubtnut</td>\n",
       "      <td>Edu Tech</td>\n",
       "      <td>SIG Global, Sequoia Capital, WaterBridge Ventu...</td>\n",
       "      <td>2,500,000</td>\n",
       "      <td>Series B</td>\n",
       "      <td>11/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zomato</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>Tiger Global, Kora</td>\n",
       "      <td>250,000,000</td>\n",
       "      <td>Venture</td>\n",
       "      <td>22/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fingerlix</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>Rhodium Trust, Accel Partners and Swiggy</td>\n",
       "      <td>2,747,045.20</td>\n",
       "      <td>Series C</td>\n",
       "      <td>19/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zolve</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Accel Partners and Lightspeed Venture Partners</td>\n",
       "      <td>1,50,00,000</td>\n",
       "      <td>Seed</td>\n",
       "      <td>17/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KreditBee</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Azim Premji’s PremjiInvest and South Korea’s M...</td>\n",
       "      <td>75,000,000</td>\n",
       "      <td>Series C</td>\n",
       "      <td>15/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pepperfry</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>InnoVen Capital</td>\n",
       "      <td>4,773,958</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>12/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Grofers</td>\n",
       "      <td>E-Commerce</td>\n",
       "      <td>SoftBank Vision Fund (SVF)</td>\n",
       "      <td>55,000,000</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>12/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nothing</td>\n",
       "      <td>Technology</td>\n",
       "      <td>GV</td>\n",
       "      <td>15,000,000</td>\n",
       "      <td>Series A</td>\n",
       "      <td>09/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SplashLearn</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>Owl Ventures</td>\n",
       "      <td>18,000,000</td>\n",
       "      <td>Series C</td>\n",
       "      <td>09/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Digit Insurance</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>A91 Partners, Faering Capital, TVS Capital Funds</td>\n",
       "      <td>1,80,00,000</td>\n",
       "      <td>Venture</td>\n",
       "      <td>15/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bombay Shaving Company</td>\n",
       "      <td>Consumer Goods Company</td>\n",
       "      <td>Reckitt Benckiser</td>\n",
       "      <td>6,172,258.50</td>\n",
       "      <td>Venture</td>\n",
       "      <td>28/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DeHaat</td>\n",
       "      <td>AgriTech Startup</td>\n",
       "      <td>Prosus Ventures</td>\n",
       "      <td>30,000,000</td>\n",
       "      <td>Series C</td>\n",
       "      <td>19/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Darwinbox</td>\n",
       "      <td>SaaS</td>\n",
       "      <td>Salesforce Ventures</td>\n",
       "      <td>15,000,000</td>\n",
       "      <td>Seed</td>\n",
       "      <td>19/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mfine</td>\n",
       "      <td>Health Tech Startup</td>\n",
       "      <td>Heritas Capital Management</td>\n",
       "      <td>16,000,000</td>\n",
       "      <td>Venture Round</td>\n",
       "      <td>18/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Udayy</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>15,000,000</td>\n",
       "      <td>Seed Funding</td>\n",
       "      <td>18/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>True Elements</td>\n",
       "      <td>Food Startup</td>\n",
       "      <td>SIDBI Venture Capital</td>\n",
       "      <td>100,000,000</td>\n",
       "      <td>Series</td>\n",
       "      <td>11/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Saveo</td>\n",
       "      <td>B2B E-commerce</td>\n",
       "      <td>Matrix Partners India, RTP Global, others</td>\n",
       "      <td>4,000,000</td>\n",
       "      <td>Seed</td>\n",
       "      <td>13/01/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Company                Industry  \\\n",
       "0                DealShare              E-commerce   \n",
       "1                 Uniphore              Technology   \n",
       "2                    Dunzo              E-commerce   \n",
       "3                   BYJU’S                Edu-tech   \n",
       "4              SkilloVilla                Edu-tech   \n",
       "5                 CityMall              E-commerce   \n",
       "6                    DotPe                 FinTech   \n",
       "7                 Doubtnut                Edu Tech   \n",
       "8                   Zomato             Hospitality   \n",
       "9                Fingerlix             Hospitality   \n",
       "10                   Zolve                 FinTech   \n",
       "11               KreditBee                 Finance   \n",
       "12               Pepperfry              E-commerce   \n",
       "13                 Grofers              E-Commerce   \n",
       "14                 Nothing              Technology   \n",
       "15             SplashLearn                  EdTech   \n",
       "16         Digit Insurance      Financial Services   \n",
       "17  Bombay Shaving Company  Consumer Goods Company   \n",
       "18                  DeHaat        AgriTech Startup   \n",
       "19               Darwinbox                    SaaS   \n",
       "20                   mfine     Health Tech Startup   \n",
       "21                   Udayy                  EdTech   \n",
       "22           True Elements            Food Startup   \n",
       "23                   Saveo          B2B E-commerce   \n",
       "\n",
       "                                        Investor_Name        Amount  \\\n",
       "0                                     Innoven Capital   250,000,000   \n",
       "1                           Sorenson Capital Partners   140,000,000   \n",
       "2                           Krishtal Advisors Pte Ltd     8,000,000   \n",
       "3          MC Global Edtech, B Capital, Baron, others   460,000,000   \n",
       "4                               Titan Capital, others   300,000,000   \n",
       "5                                      Accel Partners    11,000,000   \n",
       "6                                                PayU    27,500,000   \n",
       "7   SIG Global, Sequoia Capital, WaterBridge Ventu...     2,500,000   \n",
       "8                                  Tiger Global, Kora   250,000,000   \n",
       "9            Rhodium Trust, Accel Partners and Swiggy  2,747,045.20   \n",
       "10     Accel Partners and Lightspeed Venture Partners   1,50,00,000   \n",
       "11  Azim Premji’s PremjiInvest and South Korea’s M...    75,000,000   \n",
       "12                                    InnoVen Capital     4,773,958   \n",
       "13                         SoftBank Vision Fund (SVF)    55,000,000   \n",
       "14                                                 GV    15,000,000   \n",
       "15                                       Owl Ventures    18,000,000   \n",
       "16   A91 Partners, Faering Capital, TVS Capital Funds   1,80,00,000   \n",
       "17                                  Reckitt Benckiser  6,172,258.50   \n",
       "18                                    Prosus Ventures    30,000,000   \n",
       "19                                Salesforce Ventures    15,000,000   \n",
       "20                         Heritas Capital Management    16,000,000   \n",
       "21                                    Sequoia Capital    15,000,000   \n",
       "22                              SIDBI Venture Capital   100,000,000   \n",
       "23          Matrix Partners India, RTP Global, others     4,000,000   \n",
       "\n",
       "   Investment_Type       Dates  \n",
       "0   Debt Financing  04/03/2021  \n",
       "1         Series D  31/03/2021  \n",
       "2         Series E  30/03/2021  \n",
       "3         Series F  30/03/2021  \n",
       "4             Seed  23/03/2021  \n",
       "5         Series A  25/03/2021  \n",
       "6         Series A  26/03/2021  \n",
       "7         Series B  11/02/2021  \n",
       "8          Venture  22/02/2021  \n",
       "9         Series C  19/02/2021  \n",
       "10            Seed  17/02/2021  \n",
       "11        Series C  15/02/2021  \n",
       "12  Debt Financing  12/02/2021  \n",
       "13     Unspecified  12/02/2021  \n",
       "14        Series A  09/02/2021  \n",
       "15        Series C  09/02/2021  \n",
       "16         Venture  15/01/2021  \n",
       "17         Venture  28/01/2021  \n",
       "18        Series C  19/01/2021  \n",
       "19            Seed  19/01/2021  \n",
       "20   Venture Round  18/01/2021  \n",
       "21    Seed Funding  18/01/2021  \n",
       "22          Series  11/01/2021  \n",
       "23            Seed  13/01/2021  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Company':Company,'Industry':Industry,'Investor_Name':Investor_Name,'Amount':Amount,'Investment_Type':Investment_Type,'Dates':Dates})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0632290b",
   "metadata": {},
   "source": [
    "### 7. Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "dcb32898",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://www.digit.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4170a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "select=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[4]/ul/li[4]/a')\n",
    "select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "85192fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap=driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[5]/div[1]/div/button[2]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a12fc74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best=driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[5]/div[3]/div[3]/a/div[2]/p').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2a97774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name=[]\n",
    "br=driver.find_elements(By.TAG_NAME,'h3')\n",
    "for i in br:\n",
    "    brand_name.append(str(i.text).replace(\"\\n\",\"\"))\n",
    "os=[]\n",
    "o_s=driver.find_elements(By.XPATH,'//div[@class=\"value\"]')\n",
    "for i in o_s[0::4]:\n",
    "    os.append(str(i.text).replace(\"\\n\",\" \"))\n",
    "display=[]\n",
    "dis=driver.find_elements(By.XPATH,'//div[@class=\"value\"]')\n",
    "for i in dis[1::4]:\n",
    "    display.append(str(i.text).replace(\"\\n\",\" \"))\n",
    "\n",
    "processor=[]\n",
    "pro=driver.find_elements(By.XPATH,'//div[@class=\"value\"]')\n",
    "for i in pro[2::4]:\n",
    "    processor.append(str(i.text).replace(\"\\n\",\" \"))\n",
    "    \n",
    "memory=[]\n",
    "mem=driver.find_elements(By.XPATH,'//div[@class=\"value\"]')\n",
    "for i in mem[3::4]:\n",
    "    memory.append(str(i.text).replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d3f85c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>os</th>\n",
       "      <th>display</th>\n",
       "      <th>processor</th>\n",
       "      <th>memory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI Titan GT77-12UHS</td>\n",
       "      <td>Windows 11 Home OS</td>\n",
       "      <td>17.3\" (3840 x 2160) Display</td>\n",
       "      <td>12th Gen Intel Core i9-12900HX | NA Processor</td>\n",
       "      <td>2 TB SSD/64 GB DDR5 Memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alienware X17 R2</td>\n",
       "      <td>Windows 11 Home OS</td>\n",
       "      <td>17.3\" (1920 x 1080) Display</td>\n",
       "      <td>12th Gen Intel Core i9-12900H | 5 GHz Processor</td>\n",
       "      <td>1 TB SSD/32 GB DDR5 Memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer Predator Triton 500 SE PT516-52s</td>\n",
       "      <td>Windows 11 Home OS</td>\n",
       "      <td>16\" (2560 x 1600) Display</td>\n",
       "      <td>12th Gen Intel Core i7-12700H | 3.50 GHz Proce...</td>\n",
       "      <td>2 TB SSD/32 GB DDR5 Memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Omen By HP (16-B1371TX)</td>\n",
       "      <td>Windows 11 Home OS</td>\n",
       "      <td>16.1\" (2560 x 1440) Display</td>\n",
       "      <td>12th Gen Intel Core i7-12700H | 4.7 GHz Processor</td>\n",
       "      <td>1 TB SSD/8 GB DDR5 Memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acer Predator Helios 300 AN515-45 (NH.QBRSI.0</td>\n",
       "      <td>Windows 11 Home OS</td>\n",
       "      <td>15.6\" (2560 x 1440) Display</td>\n",
       "      <td>AMD Ryzen 9-5900HX | NA Processor</td>\n",
       "      <td>512 GB SSD/16 GB DDR4 Memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSI Delta 15 (A5EFK-083IN)</td>\n",
       "      <td>Windows 11 Home OS</td>\n",
       "      <td>15.6\" (1920 x 1080) Display</td>\n",
       "      <td>AMD 5th Gen Ryzen 9-5900HX | 3.3GHz Processor</td>\n",
       "      <td>1 TB SSD/16 GBGB DDR4 Memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Omen By HP (16-C0141AX)</td>\n",
       "      <td>Windows 11 Home OS</td>\n",
       "      <td>16.1\" (2560 x 1440) Display</td>\n",
       "      <td>AMD Ryzen™ 9 5900HX | 3.3 GHz Processor</td>\n",
       "      <td>1 TB NVMe/16 GB DDR4 Memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo Legion 5i Pro (82RF00MGIN)</td>\n",
       "      <td>Windows 11 Home OS</td>\n",
       "      <td>16\" (2560 x 1600) Display</td>\n",
       "      <td>12th Gen Intel Core i7-12700H | 2.3 GHz Processor</td>\n",
       "      <td>1 TB SSD/16 GB DDR5 Memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alienware M15 R5 Ryzen Edition Icc-C780001win</td>\n",
       "      <td>Windows 11 Home OS</td>\n",
       "      <td>15.6\" (1920 x 1080) Display</td>\n",
       "      <td>AMD Ryzen R7-5800H | 4.40 GHz Processor</td>\n",
       "      <td>512 GB SSD/16 GB DDR4 Memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo Slim 7 Gen 6 (82K8002JIN)</td>\n",
       "      <td>Windows 11 Home OS</td>\n",
       "      <td>15.6 MP | NA Display</td>\n",
       "      <td>Lenovo Ryzen 7-5800H | 3.2 GHz Processor</td>\n",
       "      <td>1 TB SSD/16 GB DDR4 Memory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      brand_name                  os  \\\n",
       "0                           MSI Titan GT77-12UHS  Windows 11 Home OS   \n",
       "1                               Alienware X17 R2  Windows 11 Home OS   \n",
       "2          Acer Predator Triton 500 SE PT516-52s  Windows 11 Home OS   \n",
       "3                        Omen By HP (16-B1371TX)  Windows 11 Home OS   \n",
       "4  Acer Predator Helios 300 AN515-45 (NH.QBRSI.0  Windows 11 Home OS   \n",
       "5                     MSI Delta 15 (A5EFK-083IN)  Windows 11 Home OS   \n",
       "6                        Omen By HP (16-C0141AX)  Windows 11 Home OS   \n",
       "7              Lenovo Legion 5i Pro (82RF00MGIN)  Windows 11 Home OS   \n",
       "8  Alienware M15 R5 Ryzen Edition Icc-C780001win  Windows 11 Home OS   \n",
       "9               Lenovo Slim 7 Gen 6 (82K8002JIN)  Windows 11 Home OS   \n",
       "\n",
       "                       display  \\\n",
       "0  17.3\" (3840 x 2160) Display   \n",
       "1  17.3\" (1920 x 1080) Display   \n",
       "2    16\" (2560 x 1600) Display   \n",
       "3  16.1\" (2560 x 1440) Display   \n",
       "4  15.6\" (2560 x 1440) Display   \n",
       "5  15.6\" (1920 x 1080) Display   \n",
       "6  16.1\" (2560 x 1440) Display   \n",
       "7    16\" (2560 x 1600) Display   \n",
       "8  15.6\" (1920 x 1080) Display   \n",
       "9         15.6 MP | NA Display   \n",
       "\n",
       "                                           processor  \\\n",
       "0      12th Gen Intel Core i9-12900HX | NA Processor   \n",
       "1    12th Gen Intel Core i9-12900H | 5 GHz Processor   \n",
       "2  12th Gen Intel Core i7-12700H | 3.50 GHz Proce...   \n",
       "3  12th Gen Intel Core i7-12700H | 4.7 GHz Processor   \n",
       "4                  AMD Ryzen 9-5900HX | NA Processor   \n",
       "5      AMD 5th Gen Ryzen 9-5900HX | 3.3GHz Processor   \n",
       "6            AMD Ryzen™ 9 5900HX | 3.3 GHz Processor   \n",
       "7  12th Gen Intel Core i7-12700H | 2.3 GHz Processor   \n",
       "8            AMD Ryzen R7-5800H | 4.40 GHz Processor   \n",
       "9           Lenovo Ryzen 7-5800H | 3.2 GHz Processor   \n",
       "\n",
       "                         memory  \n",
       "0    2 TB SSD/64 GB DDR5 Memory  \n",
       "1    1 TB SSD/32 GB DDR5 Memory  \n",
       "2    2 TB SSD/32 GB DDR5 Memory  \n",
       "3     1 TB SSD/8 GB DDR5 Memory  \n",
       "4  512 GB SSD/16 GB DDR4 Memory  \n",
       "5  1 TB SSD/16 GBGB DDR4 Memory  \n",
       "6   1 TB NVMe/16 GB DDR4 Memory  \n",
       "7    1 TB SSD/16 GB DDR5 Memory  \n",
       "8  512 GB SSD/16 GB DDR4 Memory  \n",
       "9    1 TB SSD/16 GB DDR4 Memory  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'brand_name':brand_name,'os':os,'display':display,'processor':processor,'memory':memory})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5835a9",
   "metadata": {},
   "source": [
    "### 8. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a9ba6f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"http://www.forbes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f0f7315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "select=driver.find_element(By.CLASS_NAME,\"_69hVhdY4\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1aa761ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"mpBfVZz3\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8bff5079",
   "metadata": {},
   "outputs": [],
   "source": [
    "top=driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div[1]/div/div/div[2]/ul/li[1]/div[2]/div[2]/ul/li[1]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "35bc6094",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "nme=driver.find_elements(By.XPATH,'//div[@class=\"personName\"]')\n",
    "for i in nme:\n",
    "    name.append(str(i.text).replace(\"\\n\",\"\"))\n",
    "    \n",
    "net_worth=[]\n",
    "nw=driver.find_elements(By.XPATH,'//div[@class=\"netWorth\"]')\n",
    "for i in nw:\n",
    "    net_worth.append(str(i.text).replace(\"\\n\",\"\"))\n",
    "    \n",
    "    \n",
    "age=[]\n",
    "ag=driver.find_elements(By.XPATH,'//div[@class=\"age\"]')\n",
    "for i in ag:\n",
    "    age.append(str(i.text).replace(\"\\n\",\"\"))\n",
    "    \n",
    "citizenship=[]\n",
    "ctz=driver.find_elements(By.XPATH,'//div[@class=\"countryOfCitizenship\"]')\n",
    "for i in ctz:\n",
    "    citizenship.append(str(i.text).replace(\"\\n\",\"\"))\n",
    "    \n",
    "source=[]\n",
    "src=driver.find_elements(By.XPATH,'//span[@class=\"source-text\"]')\n",
    "for i in src:\n",
    "    source.append(str(i.text).replace(\"\\n\",\"\"))\n",
    "    \n",
    "industry=[]\n",
    "ind=driver.find_elements(By.XPATH,'//div[@class=\"category\"]')\n",
    "for i in ind:\n",
    "    industry.append(str(i.text).replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e34cc56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>net worth</th>\n",
       "      <th>age</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>source</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>$219 B</td>\n",
       "      <td>50</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>$171 B</td>\n",
       "      <td>58</td>\n",
       "      <td>United States</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>$158 B</td>\n",
       "      <td>73</td>\n",
       "      <td>France</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>$129 B</td>\n",
       "      <td>66</td>\n",
       "      <td>United States</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Warren Buffett</td>\n",
       "      <td>$118 B</td>\n",
       "      <td>91</td>\n",
       "      <td>United States</td>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Marcel Herrmann Telles</td>\n",
       "      <td>$10.3 B</td>\n",
       "      <td>72</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>beer</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Leon Black</td>\n",
       "      <td>$10 B</td>\n",
       "      <td>70</td>\n",
       "      <td>United States</td>\n",
       "      <td>private equity</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Joe Gebbia</td>\n",
       "      <td>$10 B</td>\n",
       "      <td>40</td>\n",
       "      <td>United States</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>David Geffen</td>\n",
       "      <td>$10 B</td>\n",
       "      <td>79</td>\n",
       "      <td>United States</td>\n",
       "      <td>movies, record labels</td>\n",
       "      <td>Media &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Yu Renrong</td>\n",
       "      <td>$10 B</td>\n",
       "      <td>56</td>\n",
       "      <td>China</td>\n",
       "      <td>semiconductors</td>\n",
       "      <td>Manufacturing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name net worth age    citizenship  \\\n",
       "0                   Elon Musk    $219 B  50  United States   \n",
       "1                  Jeff Bezos    $171 B  58  United States   \n",
       "2    Bernard Arnault & family    $158 B  73         France   \n",
       "3                  Bill Gates    $129 B  66  United States   \n",
       "4              Warren Buffett    $118 B  91  United States   \n",
       "..                        ...       ...  ..            ...   \n",
       "195    Marcel Herrmann Telles   $10.3 B  72         Brazil   \n",
       "196                Leon Black     $10 B  70  United States   \n",
       "197                Joe Gebbia     $10 B  40  United States   \n",
       "198              David Geffen     $10 B  79  United States   \n",
       "199                Yu Renrong     $10 B  56          China   \n",
       "\n",
       "                    source               industry  \n",
       "0            Tesla, SpaceX             Automotive  \n",
       "1                   Amazon             Technology  \n",
       "2                     LVMH       Fashion & Retail  \n",
       "3                Microsoft             Technology  \n",
       "4       Berkshire Hathaway  Finance & Investments  \n",
       "..                     ...                    ...  \n",
       "195                   beer        Food & Beverage  \n",
       "196         private equity  Finance & Investments  \n",
       "197                 Airbnb             Technology  \n",
       "198  movies, record labels  Media & Entertainment  \n",
       "199         semiconductors          Manufacturing  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'name':name,'net worth':net_worth,'age':age,'citizenship':citizenship,'source':source,'industry':industry})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6533f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
